{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5495a353-7df7-4b91-8481-93372e6cff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torchvision\n",
    "import tifffile as ti\n",
    "import numpy as np\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.ops import nms\n",
    "from torch_snippets import *\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc0f34e-0e40-40fc-8a2c-040c5efe2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'diatom-model_02.pt'\n",
    "MODEL_ROOT = './model/'\n",
    "TEMP_DIR = './temp/'\n",
    "VIDEO_DIR = './videoFiles/'\n",
    "LABEL_DIR = './OutputLabels/'\n",
    "MAX_DIMENSION = 50\n",
    "MIN_DIMENSION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429dba70-47e8-4284-8823-02dc73def4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the model\n",
    "num_classes = 2\n",
    "target2label = {1: 'diatom', 0: 'background'}\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.DEFAULT')\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_ROOT + model_file))\n",
    "modelDetails = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e168134-7f68-4f17-b932-3ed9c247f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    #img = torch.tensor(img, dtype=torch.float32).permute(2,0,1)\n",
    "    img = torch.tensor(img, dtype=torch.float64).permute(2,0,1)\n",
    "    return img.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175fbe7c-0bc9-4284-8204-5f933059bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(output):\n",
    "    'convert tensors to numpy arrays'\n",
    "    bbs = output['boxes'].cpu().detach().numpy().astype(np.uint16)\n",
    "    labels = np.array([target2label[i] for i in output['labels'].cpu().detach().numpy()])\n",
    "    confs = output['scores'].cpu().detach().numpy()\n",
    "    ixs = nms(torch.tensor(bbs.astype(np.float32)), torch.tensor(confs), 0.05)\n",
    "    bbs, confs, labels = [tensor[ixs] for tensor in [bbs, confs, labels]]\n",
    "\n",
    "    if len(ixs) == 1:\n",
    "        bbs, confs, labels = [np.array([tensor]) for tensor in [bbs, confs, labels]]\n",
    "    return bbs.tolist(), confs.tolist(), labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea011981-56bc-41a5-a761-fe12b60c41ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (200046067.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [6], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    if abs(b[2] - b[0]) < MAX_DIMENSION and abs(b[3] - b[1]) < MAX_DIMENSION\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "batch_size = 61\n",
    "def getImagesFromVideo(vid, name):\n",
    "    im = ti.imread(vid)\n",
    "    df = pd.DataFrame(columns=['timestamp', 'x0', 'y0', 'x1', 'y1'])\n",
    "    count = 0\n",
    "    for i in im:\n",
    "        fig = px.imshow(i, binary_string=True)\n",
    "        fig.update_xaxes(visible=False)\n",
    "        fig.update_yaxes(visible=False)\n",
    "        fig.write_image(TEMP_DIR + name + \"_\"+ str(count) + \".png\", height=i.shape[0], width=i.shape[1])\n",
    "        count = count + 1\n",
    "        pass\n",
    "    files = glob.glob(TEMP_DIR + '/*.png')\n",
    "    img_list = find(name, files)\n",
    "    veri_img = []\n",
    "    for i in img_list:\n",
    "        veri = Image.open(i).convert(\"RGB\")\n",
    "        veri = np.array(veri.resize((1392,1040), resample=Image.Resampling.BILINEAR))/255.\n",
    "        veri = preprocess_image(veri)\n",
    "        veri_img.append(veri)\n",
    "        os.remove(i)\n",
    "        pass\n",
    "    print(f'veri_img: {len(veri_img)}')\n",
    "    for i in range(int(len(veri_img) / batch_size) + 1):\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        if start >= len(veri_img):\n",
    "            break\n",
    "            pass\n",
    "        if end > len(veri_img):\n",
    "            end = -1 # len(veri_img)\n",
    "            pass\n",
    "        print(f'start: {start} end: {end}', end='\\t')\n",
    "        outputs = model(veri_img[start:end])\n",
    "        for ix, output in enumerate(outputs):\n",
    "            bbs, confs, labels = decode_output(output)\n",
    "            filtered_bbs = []\n",
    "            for b in bbs:\n",
    "                if abs(b[2] - b[0]) < MAX_DIMENSION and abs(b[3] - b[1]) < MAX_DIMENSION and (abs(b[2] - b[0]) > MIN_DIMENSION or abs(b[3] - b[1]) > MIN_DIMENSION):\n",
    "                    temp_df = pd.DataFrame([{'timestamp': ix + start, 'x0': b[0], 'y0': b[1], 'x1': b[2], 'y1': b[3]}])\n",
    "                    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "                    filtered_bbs.append(b)\n",
    "                    pass\n",
    "                pass\n",
    "            if (ix + start) % 45 == 0: # 24 == 0:\n",
    "                show(veri_img[ix + start].cpu().permute(1,2,0), bbs=bbs)#, bbs=filtered_bbs, texts=labels, sz=15)\n",
    "                show(veri_img[ix + start].cpu().permute(1,2,0), bbs=filtered_bbs)\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    df.to_csv(LABEL_DIR + name + '.csv', index=False)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c733d2-2926-483b-bc30-6fa73d318a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar 1.tif', 'agar 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e19a4-a13f-4c4c-94a0-49dacb080e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar 2.tif', 'agar 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0918657-5a5b-4ec5-a8d3-e9a6734b79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar sw 1 (unmasked).tif', 'agar sw 1 (unmasked)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbfb177-751b-4da5-a3f9-18a5e1dd0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar sw 2.tif', 'agar sw 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7160bf-901c-481b-b3e2-08c3df17c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar sw surface 1.tif', 'agar sw surface 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df262e-0b45-405b-a723-4fcd1c53d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'agar sw surface 2.tif', 'agar sw surface 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd5014-5502-401a-b480-875cae48233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'Movie 16 5x obj.tif', 'Movie 16 5x obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576dc4a-fed7-4879-8a6c-5dca41152936",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'Movie 29 5x obj 30 degrees.tif', 'Movie 29 5x obj 30 degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e6e1a-6d9b-4a09-bab3-a21b37f54ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "getImagesFromVideo(VIDEO_DIR + 'Movie 7 5x obj cropped.tif', 'Movie 7 5x obj cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac6dca-cd6d-4de7-8d14-e29717124d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
